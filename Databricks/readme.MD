# **Databricks Overview**

**Databricks** is an open-source solution with multiple applications, built around core technologies such as **Apache Spark, Delta Lake, and MLflow**.

---

## **Core Components**

### **1. Apache Spark**
- **Fault-tolerant, Scalable, and Resilient Distributed Data (RDD) framework.**
- Enables **parallel execution** of multiple operations.

### **2. Data Lakehouse**
- A hybrid **Data Warehouse + Data Lake** architecture.
- Combines the benefits of both data warehousing and data lake solutions.

---

## **Key Concepts in Databricks**
1. **Workspace** – Centralized environment for managing resources.
2. **Notebooks** – Interactive documents for writing and executing code.
3. **Tables** – Structured datasets stored within Databricks.
4. **Clusters** – Distributed computing resources for executing workloads.
5. **Jobs** – Automated execution of workflows and scripts.
6. **Libraries** – Additional packages and dependencies for enhanced functionality.

---

## **Databricks Workspace**
- **Two types of workspaces:**
  1. **Users** – Personal workspace for individual development.
  2. **Shared** – Collaborative space for team-based projects.

- Users can create:
  - **Notebooks**
  - **Tables**
  - **Clusters**
  - **Jobs**
  - **Repositories**

---

## **Databricks Data Management Hierarchy**
- **Catalogs** → **Schemas** → Contains:
  1. **External Tables** – Tables stored outside Databricks-managed storage.
  2. **Managed Tables** – Tables managed within Databricks.
  3. **Views** – Virtual representations of table data.

---

Databricks enables efficient **big data processing, machine learning workflows, and advanced analytics**, making it a powerful platform for modern data engineering.

